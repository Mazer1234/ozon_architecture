# `controller-template`

## Назначение

Этот `docker-compose.yaml` — **шаблон одного контроллера**.
Его идея: каждый контроллер запускается отдельным `docker compose -p <project>` → у каждого своя сеть, имитация “разных NAT/локаций”.

Внутри шаблона:

* `branding_mock` — источник “данных от элементов брендинга”
* `controller` — псевдо-контроллер (в нашем шаге заглушка/placeholder)
* `netem` — имитация задержек/потерь на сети контроллера через `tc netem`

Контроллер **не публикует порты наружу**, тем самым имитируется NAT: контроллер только инициирует исходящие соединения к Kafka.

---

## Контейнеры

### 1) `branding_mock`

**Роль:** генератор “событий”/сигналов от элементов брендинга.

**Что делает в текущем шаблоне:**

* раз в 5 секунд отправляет UDP пакет `branding_ping` на `controller:9000`

**Зависимости:**

* `depends_on: controller` — чтобы “контроллер” стартовал первым.

**Переменные окружения:**
В текущей версии нет обязательных переменных.

---

### 2) `controller`

**Роль:** псевдо-контроллер (Wirenboard-like).
В дальнейшем он будет:

* принимать локальные события (например от `branding_mock`),
* отправлять телеметрию в Kafka в `TELEMETRY_TOPIC`,
* слушать команды из Kafka в `COMMAND_TOPIC` и выполнять их.

Сейчас в compose стоит “заглушка” контейнер (для фиксации архитектуры), но env уже заложены.

**Порты:**

* наружу **не публикуются** (имитация NAT)
* внутри сети может слушать `9000/udp` для `branding_mock` (если вы добавите реальный сервис)

**Важное про доступ к Kafka**

* контроллер подключается к Kafka через:

  * `KAFKA_BOOTSTRAP_SERVERS=host.docker.internal:29092`

**Почему `extra_hosts`:**

* `extra_hosts: host.docker.internal:host-gateway`
  нужно, чтобы `host.docker.internal` корректно резолвился в контейнере (особенно на Linux).

**Переменные окружения (основные):**

* `CONTROLLER_ID`
  Уникальный id контроллера (например `ctrl-00001`). Используется для:

  * ключа сообщений,
  * фильтрации команд,
  * логирования и идентификации в БД.

* `CITY`
  Город/локация (например `moscow`). Можно использовать для:

  * маршрутизации (topic per city),
  * аналитики,
  * имитации распределённой географии.

* `TELEMETRY_TOPIC`
  Kafka топик, куда контроллер публикует телеметрию.
  Пример: `telemetry.v1`

* `COMMAND_TOPIC`
  Kafka топик, откуда контроллер читает команды.
  Пример: `command.v1`

* `KAFKA_BOOTSTRAP_SERVERS`
  Адрес Kafka bootstrap. По умолчанию: `host.docker.internal:29092`
  Это важно, потому что контроллер в другой docker-сети и не видит `kafka:9092`.

* `SEND_INTERVAL_SEC`
  Интервал отправки телеметрии (в будущем). Сейчас — просто параметр для симулятора.

---

### 3) `netem`

**Роль:** симуляция плохой сети (delay/jitter/loss) на интерфейсе контроллера.

**Ключевая настройка:**

* `network_mode: "service:controller"`
  Это означает, что `netem` разделяет network namespace с `controller`, поэтому `tc netem` применяется к трафику контроллера.

**Права:**

* `cap_add: NET_ADMIN` — нужно для `tc qdisc`.

**Переменные окружения:**

* `NETEM_DELAY_MS`
  Средняя задержка в миллисекундах (например `100`).

* `NETEM_JITTER_MS`
  Джиттер к задержке в миллисекундах (например `20`).
  Если 0 — джиттер не применяется.

* `NETEM_LOSS_PCT`
  Потери пакетов в процентах (например `1` или `2.5`).

---

## Пример `.env` для одного контроллера

```env
CONTROLLER_ID=ctrl-00001
CITY=moscow

KAFKA_BOOTSTRAP_SERVERS=host.docker.internal:29092
TELEMETRY_TOPIC=telemetry.v1
COMMAND_TOPIC=command.v1

SEND_INTERVAL_SEC=5

NETEM_DELAY_MS=50
NETEM_JITTER_MS=10
NETEM_LOSS_PCT=1
```

---

## Пример запуска одного контроллера отдельным проектом

```bash
docker compose -p ctrl_00001 --env-file .env up -d
```

> За счёт `-p ctrl_00001` создаётся отдельная docker-сеть и изоляция как у “реально отдельного устройства”.

